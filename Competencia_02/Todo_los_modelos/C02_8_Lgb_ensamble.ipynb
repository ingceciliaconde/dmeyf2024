{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqIUj3DNKtjk"
   },
   "source": [
    "# 1.Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vhhu79HVkwb5",
    "outputId": "19f2ff77-f6b2-4941-fc86-8c29b97e6094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: lightgbm==4.4.0 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm==4.4.0) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm==4.4.0) (1.14.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\mconde\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna==3.6.1 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (2.0.32)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna==3.6.1) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from alembic>=1.5.0->optuna==3.6.1) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from alembic>=1.5.0->optuna==3.6.1) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from colorlog->optuna==3.6.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\mconde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\mconde\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm==4.4.0\n",
    "%pip install optuna==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cj-rL6xHlA2u",
    "outputId": "cc41281f-90a6-4ee9-ecb7-e68bbccf3521"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvQi2pqhKzvg"
   },
   "source": [
    "# 2.Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "El48ncOW-67L"
   },
   "outputs": [],
   "source": [
    "#seteo carpeta de trabajo y archivo\n",
    "dataset_path = '/home/ingceciliaconde/buckets/b1/datasets'\n",
    "modelos_path = '/home/ingceciliaconde/buckets/b1/datasets/modelos'\n",
    "db_path = '/home/ingceciliaconde/buckets/b1/datasets/db'\n",
    "exp_path ='/home/ingceciliaconde/buckets/b1/exp'\n",
    "dataset_file = 'competencia_02_fe_v1.csv.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path de trabajo local para pruebas\n",
    "# #seteo carpeta de trabajo y archivo\n",
    "dataset_path = 'C:/Users/mconde/Documents/DMEYF/Competencia_01'\n",
    "# db_path = 'C:/Users/mconde/Documents/DMEYF/Competencia_01'\n",
    "# modelos_path = 'C:/Users/mconde/Documents/DMEYF/Competencia_01'\n",
    "dataset_file = 'competencia_01.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/mconde/Documents/DMEYF/Competencia_01/competencia_01.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dataset_path}/{dataset_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oxmX_K-j_Djw"
   },
   "outputs": [],
   "source": [
    "# Lectura de datos.\n",
    "data= pd.read_csv(f\"{dataset_path}/{dataset_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RZnAj5bmTG1u"
   },
   "outputs": [],
   "source": [
    "#semillas y valores de ganancia\n",
    "semillas=[100183,200003,300017,700001,800011]\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmJcpIlLUSC_"
   },
   "outputs": [],
   "source": [
    "#meses\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "pre_post_pandemia = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908, 201909, 201910, 201911, 201912, 202001, 202002, 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "mes_train_6 = [202101, 202102, 202103, 202104, 202105, 202106]\n",
    "mes_train_12 = [202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "mes_test = 202108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_train=mes_train_all #si uso 6 meses, cambiar a mes_train_6 y si uso all, cambiar a mes_train_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxi-XXuhTXoE"
   },
   "source": [
    "## Darle valor a las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "39PeA4wJTXaH"
   },
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9zeGifHT8lj"
   },
   "source": [
    "En particular, sumaremos la clase BAJA+1, que es estructuralmente muy similar a BAJA+2, para aumentar los casos positivos. Luego, compararemos los resultados obtenidos con los de la clase con la que hemos estado trabajando hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xgi3gGCOT7do"
   },
   "outputs": [],
   "source": [
    "data['clase_binaria1'] = 0\n",
    "data['clase_binaria2'] = 0\n",
    "data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0) # solo baja +2\n",
    "data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1) #ambas bajas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9A9rmFSCAH4",
    "outputId": "fa551a52-d2c3-4504-9f5e-0622612ca6eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase_ternaria</th>\n",
       "      <th>clase_binaria1</th>\n",
       "      <th>clase_binaria2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>BAJA+2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>BAJA+2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>BAJA+2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>BAJA+2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>BAJA+2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clase_ternaria  clase_binaria1  clase_binaria2\n",
       "1047         BAJA+2               1               1\n",
       "1651         BAJA+2               1               1\n",
       "1870         BAJA+2               1               1\n",
       "1920         BAJA+2               1               1\n",
       "2039         BAJA+2               1               1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtrar por baja + 2 y mostrar clase ternaria clase binaria\n",
    "data[data['clase_ternaria'] == 'BAJA+2'][['clase_ternaria', 'clase_binaria1', 'clase_binaria2']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBsm--L6UKXy"
   },
   "source": [
    "# 3.Separa Test y Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JCsRpOncUN0P"
   },
   "outputs": [],
   "source": [
    "train_data = data[data['foto_mes'].isin(mes_train)] # train_data = data[data['foto_mes'] == mes_train]\n",
    "#test_data = data[data['foto_mes'] == mes_test]\n",
    "test_data = data[data['foto_mes'] == 202106] #solo para hacer el script, en la competencia se usará 202108\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1'] #SOLO BAJA+2\n",
    "y_train_binaria2 = train_data['clase_binaria2'] #TODAS LAS BAJAS\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTTXRb3MVJVn"
   },
   "source": [
    "# 4.Funcion de Ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a81vl1oNVINN"
   },
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "# Parámetros del modelos.\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gan_eval',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kkp-1Li6ci9z"
   },
   "source": [
    "# Corre el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Volvemos a leer el modelo.\n",
    "#model_lgb = lgb.Booster(model_file= modelos_path + 'lgbm_{}_{}.txt'.format(cantidad_meses_train,ventana))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#a. Importo librería.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkaggle_api_extended\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KaggleApi\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#b. Configura el API de Kaggle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m api \u001b[38;5;241m=\u001b[39m KaggleApi()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "#a. Importo librería.\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "#b. Configura el API de Kaggle\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos encontrados que no terminan en 0:\n",
      "['lgb_v5_semilla100183_6_3.txt', 'lgb_v5_semilla200003_6_3.txt', 'lgb_v5_semilla300017_6_3.txt', 'lgb_v5_semilla700001_6_3.txt', 'lgb_v5_semilla800011_6_3.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Patrón para nombres válidos de archivos\n",
    "# Patrón para nombres válidos de archivos, incluyendo sufijos opcionales como '_fev1'\n",
    "pattern = re.compile(r'^lgb_v\\d+_semilla\\d+_\\d+_\\d+(_\\w+)?\\.txt$')  # Archivos válidos con o sin sufijos\n",
    "no_terminan_en_0 = re.compile(r'[^0]\\.txt$')  # Excluir los que terminan en 0\n",
    "\n",
    "# Filtrar archivos que coincidan con ambos patrones\n",
    "model_files = [f for f in os.listdir(dataset_path) if pattern.match(f) and no_terminan_en_0.search(f)]\n",
    "\n",
    "# Mostrar los archivos filtrados\n",
    "print(\"Modelos encontrados que no terminan en 0:\")\n",
    "print(model_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble de probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Inicialización de DataFrame para almacenar todas las predicciones\n",
    "df_predicciones = pd.DataFrame()\n",
    "\n",
    "# Bucle sobre cada archivo de modelo para cargar y predecir\n",
    "for model_file in model_files:\n",
    "    model_path = os.path.join(dataset_path, model_file)\n",
    "    model_lgb = lgb.Booster(model_file=model_path)\n",
    "    \n",
    "    # Copia X_test para evitar añadir múltiples veces la columna 'Probabilidad'\n",
    "    X_test_copy = X_test.copy()\n",
    "    \n",
    "    # Predecir con el modelo cargado y almacenar las probabilidades\n",
    "    predicciones = model_lgb.predict(X_test_copy)\n",
    "    df_predicciones[model_file] = predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que ambos DataFrames tienen el mismo índice\n",
    "if not df_predicciones.index.equals(X_test.index):\n",
    "    print(\"Los índices no son iguales. Realineando...\")\n",
    "    df_predicciones.index = X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las columnas esperadas estén presentes y que no haya NaNs\n",
    "print(df_predicciones.head())\n",
    "print(\"¿Hay valores NaN en las predicciones?:\", df_predicciones.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media de las predicciones de todos los modelos\n",
    "X_test['Probabilidad'] = df_predicciones.mean(axis=1)\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver el DataFrame final para confirmar que los datos son correctos\n",
    "print(X_test[['numero_de_cliente', 'Probabilidad']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "# Asegúrate de que num_subida_kaggle esté inicializado\n",
    "# Parámetros de tu competencia y subidas\n",
    "competencia = 'dm-ey-f-2024-segunda'\n",
    "num_subida_kaggle = 1  # o cargar el último valor si estás continuando subidas previas\n",
    "\n",
    "# Cortes candidatos y subidas\n",
    "cortes = range(9000, 14000, 500)\n",
    "for envios in cortes:\n",
    "    tb_entrega['Predicted'] = 0\n",
    "    tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "    resultados = tb_entrega[['numero_de_cliente', 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "    nombre_archivo = f\"C2_CC_30_20_12_fev1_ensamblepromedio{num_subida_kaggle}.csv\"\n",
    "    ruta_archivo = f\"{exp_path}/{nombre_archivo}\"\n",
    "    resultados.to_csv(ruta_archivo, index=False)\n",
    "    \n",
    "     mensaje = f'Archivo {nombre_archivo}. Ensamble de los tres modelos de train 30_20_12, fev1, punto_corte: {envios}.'\n",
    "    \n",
    "    # Envío a Kaggle\n",
    "    if num_subida_kaggle <= 15:\n",
    "        api.competition_submit(file_name=ruta_archivo, message=mensaje, competition=competencia)\n",
    "        print(\"Submission successful!\")\n",
    "    else:\n",
    "        print(\"Esperamos 30 segundos...\")\n",
    "        time.sleep(30)\n",
    "        api.competition_submit(file_name=ruta_archivo, message=mensaje, competition=competencia)\n",
    "        print(\"Submission successful!\")\n",
    "    \n",
    "    num_subida_kaggle += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tb_entrega' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtb_entrega\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tb_entrega' is not defined"
     ]
    }
   ],
   "source": [
    "#quiero calcular la ganancia de cada uno de los cortes\n",
    "# Cortes candidatos y subidas\n",
    "cortes = range(9000, 14000, 500)\n",
    "for envios in cortes:\n",
    "    tb_entrega['Predicted'] = 0\n",
    "    tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "    resultados = tb_entrega[['numero_de_cliente', 'Predicted']].reset_index(drop=True)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
